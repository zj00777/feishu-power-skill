#!/usr/bin/env python3
"""
report_generator.py â€” å®šæ—¶æŠ¥å‘Šç”Ÿæˆå™¨
æ”¯æŒå¤šç§æŠ¥å‘Šç±»å‹ï¼ˆå®¡è®¡/æ•°æ®æ‘˜è¦/è‡ªå®šä¹‰æ¨¡æ¿ï¼‰ï¼Œå¯é€šè¿‡ YAML é…ç½®è°ƒåº¦ã€‚
è®¾è®¡ä¸º cron job æˆ– CLI ç›´æ¥è°ƒç”¨ã€‚

ç”¨æ³•:
  # ä»è°ƒåº¦é…ç½®è¿è¡Œæ‰€æœ‰åˆ°æœŸä»»åŠ¡
  python3 report_generator.py run --schedule schedule.yaml

  # è¿è¡ŒæŒ‡å®šä»»åŠ¡
  python3 report_generator.py run --schedule schedule.yaml --job daily_audit

  # åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡
  python3 report_generator.py list --schedule schedule.yaml

  # å•æ¬¡å®¡è®¡æŠ¥å‘Šï¼ˆä¸éœ€è¦è°ƒåº¦é…ç½®ï¼‰
  python3 report_generator.py audit --demo --output report.md

  # å•æ¬¡æ¨¡æ¿æŠ¥å‘Š
  python3 report_generator.py template --app <token> --table <id> --template <path> --publish
"""

import argparse
import json
import os
import sys
import time
import yaml
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any

# æ·»åŠ è„šæœ¬ç›®å½•åˆ° path
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, SCRIPT_DIR)

# é»˜è®¤è·¯å¾„
CONFIGS_DIR = os.path.join(SCRIPT_DIR, "..", "configs")
TEMPLATES_DIR = os.path.join(SCRIPT_DIR, "..", "templates")
STATE_FILE = os.path.join(SCRIPT_DIR, "..", ".report_state.json")

# å»¶è¿Ÿå¯¼å…¥ç¼“å­˜
_modules = {}


def _import(name: str):
    """æŒ‰éœ€å¯¼å…¥æ¨¡å—ï¼Œè‡ªåŠ¨å¤„ç†é£ä¹¦å‡­è¯ç¼ºå¤±çš„æƒ…å†µ"""
    if name in _modules:
        return _modules[name]
    patched = False
    if not os.environ.get("FEISHU_APP_ID"):
        os.environ["FEISHU_APP_ID"] = "_placeholder_"
        os.environ["FEISHU_APP_SECRET"] = "_placeholder_"
        patched = True
    mod = __import__(name)
    _modules[name] = mod
    if patched:
        os.environ.pop("FEISHU_APP_ID", None)
        os.environ.pop("FEISHU_APP_SECRET", None)
    return mod


# ============================================================
# è°ƒåº¦çŠ¶æ€ç®¡ç†
# ============================================================

def load_state() -> Dict:
    if os.path.exists(STATE_FILE):
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def save_state(state: Dict):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)


def is_job_due(job: Dict, state: Dict) -> bool:
    """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦åˆ°æœŸ

    schedule æ ¼å¼:
      frequency: daily | weekly | monthly | hourly
      time: "09:00"
      day_of_week: 1        # weekly: å‘¨ä¸€=1 ... å‘¨æ—¥=7
      day_of_month: 1       # monthly: æ¯æœˆå‡ å·
      interval_hours: 4     # hourly: é—´éš”å°æ—¶æ•°
    """
    job_id = job["id"]
    schedule = job.get("schedule", {})
    freq = schedule.get("frequency", "daily")
    now = datetime.now()

    last_run_str = state.get(job_id, {}).get("last_run")
    last_run = datetime.fromisoformat(last_run_str) if last_run_str else None

    if freq == "hourly":
        interval = schedule.get("interval_hours", 1)
        if not last_run:
            return True
        return (now - last_run).total_seconds() >= interval * 3600

    if freq == "daily":
        h, m = map(int, schedule.get("time", "09:00").split(":"))
        if now < now.replace(hour=h, minute=m, second=0, microsecond=0):
            return False
        return not (last_run and last_run.date() == now.date())

    if freq == "weekly":
        dow = schedule.get("day_of_week", 1)
        if now.isoweekday() != dow:
            return False
        h, m = map(int, schedule.get("time", "09:00").split(":"))
        if now < now.replace(hour=h, minute=m, second=0, microsecond=0):
            return False
        return not (last_run and last_run.date() == now.date())

    if freq == "monthly":
        dom = schedule.get("day_of_month", 1)
        if now.day != dom:
            return False
        h, m = map(int, schedule.get("time", "09:00").split(":"))
        if now < now.replace(hour=h, minute=m, second=0, microsecond=0):
            return False
        return not (last_run and last_run.date() == now.date())

    return False


# ============================================================
# æŠ¥å‘Šæ‰§è¡Œå™¨
# ============================================================

def run_audit_report(job: Dict) -> Dict:
    """æ‰§è¡Œå®¡è®¡æŠ¥å‘Š

    params: app_token, sales_table, config, folder_token,
            publish(bool), output_local, use_demo(bool)
    """
    ra = _import("retail_audit")
    params = job.get("params", {})
    use_demo = params.get("use_demo", False)

    config_path = params.get("config")
    if config_path and not os.path.isabs(config_path):
        config_path = os.path.join(CONFIGS_DIR, config_path)
    cfg = ra.load_config(config_path)

    if use_demo:
        stores = ra.generate_demo_data(50)
        data_source = "Demo æ¨¡æ‹Ÿæ•°æ®ï¼ˆ50å®¶é—¨åº—ï¼‰"
    else:
        api = _import("feishu_api")
        app_token = params["app_token"]
        sales_table = params["sales_table"]
        records = api.bitable_list_all_records(app_token, sales_table)
        stores = [r.get("fields", {}) for r in records]
        data_source = f"Bitable {app_token}/{sales_table}ï¼ˆ{len(stores)} å®¶é—¨åº—ï¼‰"

    result = ra.run_audit(stores, config=cfg)
    md = ra.generate_report_markdown(result)

    output = {
        "type": "audit",
        "data_source": data_source,
        "summary": result["summary"],
        "store_count": result["total_stores"],
    }

    local_path = params.get("output_local")
    if local_path:
        os.makedirs(os.path.dirname(local_path) or ".", exist_ok=True)
        with open(local_path, "w", encoding="utf-8") as f:
            f.write(md)
        output["local_path"] = local_path

    if params.get("publish", False):
        doc_token = ra.publish_report_to_feishu(md, folder_token=params.get("folder_token"))
        output["doc_token"] = doc_token
        output["url"] = f"https://my.feishu.cn/docx/{doc_token}"

    return output


def run_template_report(job: Dict) -> Dict:
    """æ‰§è¡Œæ¨¡æ¿æŠ¥å‘Š

    params: app_token, table_id, template, title, group_by,
            filter, folder_token, publish(bool), output_local, extra_context
    """
    dw = _import("doc_workflow")
    params = job.get("params", {})

    template_path = params["template"]
    if not os.path.isabs(template_path):
        template_path = os.path.join(TEMPLATES_DIR, template_path)
    if not os.path.exists(template_path):
        raise FileNotFoundError(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {template_path}")

    app_token = params["app_token"]
    table_id = params["table_id"]
    output = {"type": "template", "template": template_path}

    if params.get("publish", False):
        result = dw.bitable_to_doc(
            app_token, table_id, template_path,
            title=params.get("title"),
            group_by=params.get("group_by"),
            filter_str=params.get("filter"),
            folder_token=params.get("folder_token"),
            output_local=params.get("output_local"),
            extra_context=params.get("extra_context"),
        )
        output.update(result)
    else:
        ctx = dw.build_context_from_bitable(
            app_token, table_id,
            group_by=params.get("group_by"),
            filter_str=params.get("filter"),
            extra=params.get("extra_context"),
        )
        with open(template_path, "r", encoding="utf-8") as f:
            template = f.read()
        rendered = dw.render_template(template, ctx)

        local_path = params.get("output_local")
        if local_path:
            os.makedirs(os.path.dirname(local_path) or ".", exist_ok=True)
            with open(local_path, "w", encoding="utf-8") as f:
                f.write(rendered)
            output["local_path"] = local_path
        else:
            output["content"] = rendered

    return output


def run_custom_report(job: Dict) -> Dict:
    """æ‰§è¡Œè‡ªå®šä¹‰è„šæœ¬æŠ¥å‘Š

    params: script, args(list)
    """
    import subprocess
    params = job.get("params", {})
    script = params["script"]
    if not os.path.isabs(script):
        script = os.path.join(SCRIPT_DIR, script)

    cmd = [sys.executable, script] + params.get("args", [])
    result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
    return {
        "type": "custom",
        "script": script,
        "returncode": result.returncode,
        "stdout": result.stdout[-2000:] if result.stdout else "",
        "stderr": result.stderr[-1000:] if result.stderr else "",
    }


REPORT_RUNNERS = {
    "audit": run_audit_report,
    "template": run_template_report,
    "custom": run_custom_report,
}


# ============================================================
# è°ƒåº¦å¼•æ“
# ============================================================

def load_schedule(path: str) -> List[Dict]:
    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)
    jobs = data.get("jobs", [])
    for job in jobs:
        if "id" not in job:
            job["id"] = job.get("name", "unnamed").replace(" ", "_").lower()
    return jobs


def run_due_jobs(schedule_path: str, force_job: Optional[str] = None) -> List[Dict]:
    """è¿è¡Œæ‰€æœ‰åˆ°æœŸä»»åŠ¡ï¼ˆæˆ– force_job æŒ‡å®šçš„å•ä¸ªä»»åŠ¡ï¼‰"""
    jobs = load_schedule(schedule_path)
    state = load_state()
    results = []

    for job in jobs:
        if not job.get("enabled", True):
            continue
        job_id = job["id"]
        if force_job and job_id != force_job:
            continue
        if not force_job and not is_job_due(job, state):
            continue

        runner = REPORT_RUNNERS.get(job.get("type", "audit"))
        if not runner:
            print(f"âŒ æœªçŸ¥æŠ¥å‘Šç±»å‹: {job.get('type')} (job: {job_id})", file=sys.stderr)
            continue

        print(f"â–¶ æ‰§è¡Œä»»åŠ¡: {job.get('name', job_id)} ({job.get('type', 'audit')})", flush=True)
        start = time.time()

        try:
            output = runner(job)
            elapsed = time.time() - start
            output.update({"job_id": job_id, "elapsed_seconds": round(elapsed, 1), "status": "success"})
            results.append(output)
            state[job_id] = {"last_run": datetime.now().isoformat(), "last_status": "success", "last_elapsed": round(elapsed, 1)}
            url = output.get("url", "")
            print(f"  âœ… å®Œæˆ ({elapsed:.1f}s){' â†’ ' + url if url else ''}", flush=True)
        except Exception as e:
            elapsed = time.time() - start
            err = str(e)
            results.append({"job_id": job_id, "status": "error", "error": err, "elapsed_seconds": round(elapsed, 1)})
            state[job_id] = {"last_run": datetime.now().isoformat(), "last_status": "error", "last_error": err[:500]}
            print(f"  âŒ å¤±è´¥: {err[:200]}", file=sys.stderr, flush=True)

    save_state(state)
    return results


def list_jobs(schedule_path: str):
    jobs = load_schedule(schedule_path)
    state = load_state()
    print(f"é…ç½®: {schedule_path}")
    print(f"ä»»åŠ¡æ•°é‡: {len(jobs)}\n")
    for job in jobs:
        job_id = job["id"]
        enabled = "âœ…" if job.get("enabled", True) else "â¸ï¸"
        schedule = job.get("schedule", {})
        job_state = state.get(job_id, {})
        due = " ğŸ“Œ åˆ°æœŸ" if is_job_due(job, state) else ""
        print(f"  {enabled} {job.get('name', job_id)}")
        print(f"     ID: {job_id} | ç±»å‹: {job.get('type', 'audit')} | é¢‘ç‡: {schedule.get('frequency', 'daily')} {schedule.get('time', '')}")
        print(f"     ä¸Šæ¬¡: {job_state.get('last_run', 'ä»æœªè¿è¡Œ')} ({job_state.get('last_status', '-')}){due}\n")


# ============================================================
# CLI
# ============================================================

def main():
    parser = argparse.ArgumentParser(description="å®šæ—¶æŠ¥å‘Šç”Ÿæˆå™¨")
    sub = parser.add_subparsers(dest="command", required=True)

    p_run = sub.add_parser("run", help="è¿è¡Œè°ƒåº¦ä»»åŠ¡")
    p_run.add_argument("--schedule", required=True, help="è°ƒåº¦é…ç½®æ–‡ä»¶ (YAML)")
    p_run.add_argument("--job", help="åªè¿è¡ŒæŒ‡å®šä»»åŠ¡ ID")
    p_run.add_argument("--json", action="store_true", help="JSON æ ¼å¼è¾“å‡º")

    p_list = sub.add_parser("list", help="åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡")
    p_list.add_argument("--schedule", required=True, help="è°ƒåº¦é…ç½®æ–‡ä»¶ (YAML)")

    p_audit = sub.add_parser("audit", help="å•æ¬¡å®¡è®¡æŠ¥å‘Š")
    p_audit.add_argument("--app", help="Bitable app token")
    p_audit.add_argument("--table", help="é”€å”®æ•°æ®è¡¨ ID")
    p_audit.add_argument("--config", help="å®¡è®¡è§„åˆ™é…ç½®æ–‡ä»¶")
    p_audit.add_argument("--publish", action="store_true", help="å‘å¸ƒåˆ°é£ä¹¦")
    p_audit.add_argument("--folder", help="é£ä¹¦æ–‡ä»¶å¤¹ token")
    p_audit.add_argument("--output", help="æœ¬åœ°ä¿å­˜è·¯å¾„")
    p_audit.add_argument("--demo", action="store_true", help="ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")

    p_tpl = sub.add_parser("template", help="å•æ¬¡æ¨¡æ¿æŠ¥å‘Š")
    p_tpl.add_argument("--app", required=True, help="Bitable app token")
    p_tpl.add_argument("--table", required=True, help="æ•°æ®è¡¨ ID")
    p_tpl.add_argument("--template", required=True, help="æ¨¡æ¿æ–‡ä»¶è·¯å¾„")
    p_tpl.add_argument("--title", help="æ–‡æ¡£æ ‡é¢˜")
    p_tpl.add_argument("--group-by", help="åˆ†ç»„å­—æ®µ")
    p_tpl.add_argument("--filter", help="è¿‡æ»¤æ¡ä»¶")
    p_tpl.add_argument("--publish", action="store_true", help="å‘å¸ƒåˆ°é£ä¹¦")
    p_tpl.add_argument("--folder", help="é£ä¹¦æ–‡ä»¶å¤¹ token")
    p_tpl.add_argument("--output", help="æœ¬åœ°ä¿å­˜è·¯å¾„")

    sub.add_parser("status", help="æŸ¥çœ‹è¿è¡ŒçŠ¶æ€")

    args = parser.parse_args()

    if args.command == "run":
        results = run_due_jobs(args.schedule, force_job=args.job)
        if args.json:
            print(json.dumps(results, ensure_ascii=False, indent=2))
        elif not results:
            print("æ²¡æœ‰åˆ°æœŸä»»åŠ¡éœ€è¦æ‰§è¡Œã€‚")

    elif args.command == "list":
        list_jobs(args.schedule)

    elif args.command == "audit":
        job = {"id": "cli_audit", "type": "audit", "params": {
            "use_demo": args.demo, "publish": args.publish,
            "output_local": args.output, "folder_token": args.folder, "config": args.config,
        }}
        if args.app:
            job["params"]["app_token"] = args.app
        if args.table:
            job["params"]["sales_table"] = args.table
        print(json.dumps(run_audit_report(job), ensure_ascii=False, indent=2))

    elif args.command == "template":
        job = {"id": "cli_template", "type": "template", "params": {
            "app_token": args.app, "table_id": args.table, "template": args.template,
            "title": args.title, "group_by": args.group_by, "filter": args.filter,
            "publish": args.publish, "folder_token": args.folder, "output_local": args.output,
        }}
        print(json.dumps(run_template_report(job), ensure_ascii=False, indent=2))

    elif args.command == "status":
        state = load_state()
        if not state:
            print("æš‚æ— è¿è¡Œè®°å½•ã€‚")
        else:
            print("è¿è¡ŒçŠ¶æ€:")
            for job_id, info in sorted(state.items()):
                emoji = "âœ…" if info.get("last_status") == "success" else "âŒ"
                print(f"  {emoji} {job_id}")
                print(f"     ä¸Šæ¬¡è¿è¡Œ: {info.get('last_run', '-')}")
                if info.get("last_error"):
                    print(f"     é”™è¯¯: {info['last_error'][:100]}")
                print()


if __name__ == "__main__":
    main()
